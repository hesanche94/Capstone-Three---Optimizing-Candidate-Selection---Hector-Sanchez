{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad95609-3cf9-48dd-9cfd-878ad0af2f4e",
   "metadata": {},
   "source": [
    "# **Optimizing Candidate Selection Using Recruitment Data - Preprocessing and Training Data Development - Hector Sanchez**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc99731-f422-473e-89d1-93a3919f4175",
   "metadata": {},
   "source": [
    "**Preprocessing and Training Data Development Plan**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031b6d77-2683-415e-ba14-b39b1f927522",
   "metadata": {},
   "source": [
    "1. Load and Review the Most Current Data\n",
    "\n",
    "   Objective: In this step, we'll start by loading our 'final_cleaned_encoded_recruitment_data.csv' file/dataset. The goal is to ensure that we have a clear understanding of the dataset's current structure so that we know what steps need to be taken for further processing. We'll start by importing any necessary and useful libraries (such as pandas, numpy, scikit-learn) and then load the dataset. Next, we'll use .head() and .info() to view the first few rows of the dataset, and also to check the data types of each feature. Once we verify the data type of each feature, we can move on to the next step.\n",
    "   \n",
    "2. Create Dummy Variables if Necessary\n",
    "\n",
    "   Objective: In this next step we will ensure that all of the categorical features are ready for modeling. In the original dataset, the categorical features were 'Gender', 'EducationLevel', and 'RecruitmentStrategy.' We one hot encoded RecuitmentStrategy in our Data Wrangling notebook. We also encoded 'Gender', and 'EducationLevel' in our Exploratory Data Analysis notebook. IF it seems that any columns aren't ready for modeling, we will use pd.get_dummies() to one hot encode them. We will move on to the next step once we confirm that the data is fully encoded. \n",
    "   \n",
    "3. Scale Numeric Features\n",
    "\n",
    "   Objective: In this step we wil focus on standardizing the numeric features in our dataset so that they are all on a similar scale. We will use a scaler from sklearn.preprocessing to scale the numeric features, and we'll fit the scaler on the entire dataset.\n",
    "   \n",
    "4. Perform a Train-Test Split\n",
    "\n",
    "   Objective: We will focus on splitting our data into training and testing sets that we can use to evaluate our models' performance. We will need to define our target variable and the feature variables. We will also split our data into subsets of 80% training and 20% testing. \n",
    "   \n",
    "5. Save the Preprocessed Dataset for Future Use\n",
    "\n",
    "   Objective: We will save our preprocessed and split dataset for use in our modeling notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7049a9fa-04f4-477c-900c-50ef2d7f9415",
   "metadata": {},
   "source": [
    "**Load Packages and Review Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d84b1bf-8df2-4fa2-9272-0da5c723df15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll start by importing the necessary libraries and packages\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ad7f22c-105f-4d5a-838e-c1eaa4bd3dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we'll load the fully cleaned and encoded dataset\n",
    "\n",
    "file_path = 'C:/Users/hecsa/Springboard/Springboard Github/Springboard/Data Science Capstone Three/datasets/final_cleaned_encoded_recruitment_data.csv'\n",
    "recruitment_data_cleaned_encoded = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e60f1b48-a43c-4304-a0c9-a497bf37b950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>ExperienceYears</th>\n",
       "      <th>PreviousCompanies</th>\n",
       "      <th>DistanceFromCompany</th>\n",
       "      <th>InterviewScore</th>\n",
       "      <th>SkillScore</th>\n",
       "      <th>PersonalityScore</th>\n",
       "      <th>HiringDecision</th>\n",
       "      <th>Strategy_Aggressive</th>\n",
       "      <th>Strategy_Moderate</th>\n",
       "      <th>Strategy_Conservative</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>EducationLevel_Bachelor's Type 2</th>\n",
       "      <th>EducationLevel_Master's</th>\n",
       "      <th>EducationLevel_PhD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>26.783828</td>\n",
       "      <td>48</td>\n",
       "      <td>78</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>25.862694</td>\n",
       "      <td>35</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9.920805</td>\n",
       "      <td>20</td>\n",
       "      <td>67</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6.407751</td>\n",
       "      <td>36</td>\n",
       "      <td>27</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>43.105343</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  ExperienceYears  PreviousCompanies  DistanceFromCompany  \\\n",
       "0   26                0                  3            26.783828   \n",
       "1   39               12                  3            25.862694   \n",
       "2   48                3                  2             9.920805   \n",
       "3   34                5                  2             6.407751   \n",
       "4   30                6                  1            43.105343   \n",
       "\n",
       "   InterviewScore  SkillScore  PersonalityScore  HiringDecision  \\\n",
       "0              48          78                91               1   \n",
       "1              35          68                80               1   \n",
       "2              20          67                13               0   \n",
       "3              36          27                70               0   \n",
       "4              23          52                85               0   \n",
       "\n",
       "   Strategy_Aggressive  Strategy_Moderate  Strategy_Conservative  Gender_Male  \\\n",
       "0                 True              False                  False        False   \n",
       "1                False               True                  False        False   \n",
       "2                False               True                  False         True   \n",
       "3                False              False                   True        False   \n",
       "4                False               True                  False         True   \n",
       "\n",
       "   EducationLevel_Bachelor's Type 2  EducationLevel_Master's  \\\n",
       "0                              True                    False   \n",
       "1                             False                    False   \n",
       "2                              True                    False   \n",
       "3                              True                    False   \n",
       "4                             False                    False   \n",
       "\n",
       "   EducationLevel_PhD  \n",
       "0               False  \n",
       "1                True  \n",
       "2               False  \n",
       "3               False  \n",
       "4               False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilize .head() to show the first few rows of the dataset\n",
    "\n",
    "recruitment_data_cleaned_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9358b462-73d4-4ffa-a990-ebf6e1c0254a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 15 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   Age                               1500 non-null   int64  \n",
      " 1   ExperienceYears                   1500 non-null   int64  \n",
      " 2   PreviousCompanies                 1500 non-null   int64  \n",
      " 3   DistanceFromCompany               1500 non-null   float64\n",
      " 4   InterviewScore                    1500 non-null   int64  \n",
      " 5   SkillScore                        1500 non-null   int64  \n",
      " 6   PersonalityScore                  1500 non-null   int64  \n",
      " 7   HiringDecision                    1500 non-null   int64  \n",
      " 8   Strategy_Aggressive               1500 non-null   bool   \n",
      " 9   Strategy_Moderate                 1500 non-null   bool   \n",
      " 10  Strategy_Conservative             1500 non-null   bool   \n",
      " 11  Gender_Male                       1500 non-null   bool   \n",
      " 12  EducationLevel_Bachelor's Type 2  1500 non-null   bool   \n",
      " 13  EducationLevel_Master's           1500 non-null   bool   \n",
      " 14  EducationLevel_PhD                1500 non-null   bool   \n",
      "dtypes: bool(7), float64(1), int64(7)\n",
      "memory usage: 104.1 KB\n"
     ]
    }
   ],
   "source": [
    "# Utilize .info() to check on the data types \n",
    "# This will help identify numerical and categorical features\n",
    "\n",
    "recruitment_data_cleaned_encoded.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b60f99-7603-414b-8c52-9eb47ab2d635",
   "metadata": {},
   "source": [
    "In this step, we focused on loading and reviewing our dataset in order to ensure that we can move forward with preprocesing. We started by importing the necessary packages: pandas for data manipulation, train_test_split from sklearn.model_selection, and StandardScaler, MinMaxScaler from  sklearn.preprocessing. \n",
    "\n",
    "Our initial call of .head() helped us ensure that our work from the previous Wrangling and EDA steps was probably reflected in our dataset. Also, our call of .info() helped us verify that our features are all in the proper data type for modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7164b3-c5d2-416f-aad5-0bc599da4095",
   "metadata": {},
   "source": [
    "**Create Dummy Variables if Necessary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b82742d8-03cf-49ac-b23a-9b29ee41261a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: Index([], dtype='object')\n",
      "All categorical data is already encoded.\n"
     ]
    }
   ],
   "source": [
    "# Utilize the following code to check for any remaining categorical columns\n",
    "\n",
    "categorical_columns = recruitment_data_cleaned_encoded.select_dtypes(include=['object', 'category']).columns\n",
    "print(\"Categorical columns:\", categorical_columns)\n",
    "\n",
    "if len(categorical_columns) > 0:\n",
    "    recruitment_data_cleaned_encoded.get_dummies(recruitment_data_cleaned_encoded, columns=categorical_colummns, drop_first=True)\n",
    "else:\n",
    "    print(\"All categorical data is already encoded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0541385a-17e6-41a1-ba3d-8dccc4b030a8",
   "metadata": {},
   "source": [
    "While this step may seem redundant due to the work that we did in our previous notebooks, we still used the code above to further clarify that our data is ready. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc88fb3d-d434-4b7a-96b8-09ff6e9045aa",
   "metadata": {},
   "source": [
    "**Scale Numeric Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46920320-60d7-4fe5-8302-ff3c92902476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by identifying the numeric columns that need to be scaled\n",
    "\n",
    "numeric_columns = recruitment_data_cleaned_encoded.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "numeric_columns.remove('HiringDecision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39454b49-bb3a-445f-8ce6-ddd959d86354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Scaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the scaler on the numeric features\n",
    "\n",
    "recruitment_data_cleaned_encoded[numeric_columns] = scaler.fit_transform(recruitment_data_cleaned_encoded[numeric_columns])\n",
    "\n",
    "# Utilize .head() to show the first few rows of the dataset\n",
    "# This will confirm the scaling has been applied\n",
    "\n",
    "recruitment_data_cleaned_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1b8c56-757a-4cf9-b922-613c588711a7",
   "metadata": {},
   "source": [
    "In this step, I selected to use StandardScaler solely based on the fact that it's recommended for most algorithms. I could also use MinMaxScaler, but it's strictly as option for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc460ff-f69c-4c6a-8e44-9b5d088cb49c",
   "metadata": {},
   "source": [
    "**Perform a Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20d9c41c-7b61-4fba-81ce-f3211be5c2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1200, 14) (1200,)\n",
      "Testing set shape: (300, 14) (300,)\n"
     ]
    }
   ],
   "source": [
    "# Define features for (X) and for our target variable (y)\n",
    "\n",
    "X = recruitment_data_cleaned_encoded.drop('HiringDecision', axis=1)\n",
    "y = recruitment_data_cleaned_encoded['HiringDecision']\n",
    "\n",
    "# Split the data using a 80% train, and 20% test ratio\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shape of the splits\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08b6605-6248-4b56-b44f-8e82078a7894",
   "metadata": {},
   "source": [
    "In this step, we performed a train test split as the final step in this notebook (aside form saving the data). Our call on train_test_split split the dataset into 80% train and 20% test. \n",
    "This split results in X_train having 1200 rows and 14 columns, and X_test has 300 rows and 14 columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8c8862-c364-4248-9cf8-acee55c959a3",
   "metadata": {},
   "source": [
    "**Save the Preprocessed Dataset for Future Use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb721aed-a9d7-4314-be86-608dec558a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will save the training and testing sets\n",
    "\n",
    "X_train.to_csv('X_train.csv', index=False)\n",
    "X_test.to_csv('X_test.csv', index=False)\n",
    "y_train.to_csv('y_train.csv', index=False)\n",
    "y_test.to_csv('y_test.csv', index=False)\n",
    "\n",
    "# We will also save the full preprocessed DataFrame for future reference\n",
    "\n",
    "recruitment_data_cleaned_encoded.to_csv('final_preprocessed_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
